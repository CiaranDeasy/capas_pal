%%%%%%%%%%%%%%% Updated by MR March 2007 %%%%%%%%%%%%%%%%
\documentclass[12pt]{article}
\usepackage{a4wide}

\newcommand{\al}{$<$}
\newcommand{\ar}{$>$}

\parindent 0pt
\parskip 6pt

\begin{document}

\thispagestyle{empty}

\rightline{\large{Ciaran Deasy}}
\medskip
\rightline{\large{Churchill College}}
\medskip
\rightline{\large{cfd27}}

\vfil

\centerline{\large Computer Science Tripos, Part II}
\vspace{0.4in}
\centerline{\Large\bf A Prolog Compiler with Continuations}
\vspace{0.3in}
\centerline{\large 2013/14}
\vspace{2.5in}

\newpage
\hspace{5px}
\newpage

\vfil

\centerline{\large Ciaran Deasy, Churchill College}
\vspace{0.4in}
\centerline{\Large\bf A Prolog Compiler with Continuations}
\vspace{0.3in}
\centerline{\large Computer Science Tripos, Part II, 2014}
\vspace{0.1in}
\centerline{ ***** words}
\vspace{0.25in}

{\bf Author:} Ciaran Deasy\\
{\bf College:} Churchill College

\vspace{0.25in}

{\bf Project Originator:} Alan Mycroft\\
{\bf Project Supervisor:} Alan Mycroft

\vspace{0.25in}

{\bf Aim:}\\
The purpose of this project was to produce an implementation of the Prolog programming language. The implementation was to be written in ML and use continuation-passing style to implement the traditionally awkward backtracking behaviour of Prolog in a simple and intuitive way. The implementation was to be extensive, but not exhaustive. It was to include both an interpreter and a compiler to source ML. %TODO

\vspace{0.25in}

{\bf Work completed:}\\
A working implementation of Prolog was built, using continuation-passing style as planned. %TODO

\vspace{0.25in}

{\bf Special Difficulties:} None

{\bf Declaration of Originality:}
I, Ciaran Deasy of Churchill College, being a candidate for Part II of the Computer Science Tripos, hereby declare that this dissertation and the work described in it are my own work, unaided except as may be specified below, and that the dissertation does not contain material that has already been used to any substantial extent for a comparable purpose. 

Signed %TODO

Date %TODO

\vfil
\eject

\section*{Table of Contents}

%TODO
[TODO]

\newpage

\section{Introduction}

% Introduction and Preparation: 3100 words

% Talk about the WAM
% Talk about pure Prolog
% Talk about Prolog generally
% Byrd Box Model
% SML/NJ
% Unification of terms

\subsection{Project Overview}

The purpose of this project was to produce an implementation of the Prolog programming language, written in ML. 
This implementation consisted of an interpreter, taking as input a valid pure Prolog source file and outputting the result of running that file, and a compiler, taking the same input and outputting an equivalent ML program. 
The internal implementation was to use continuation-passing style, a technique that has been previously used to good effect to implement backtracking algorithms, with the aim of deciding whether this was a useful and intuitive way of implementing the Prolog language. 
The project also sought to investigate the potential gains of pre-compiling a Prolog program, compared with simply interpreting it.

\subsection{Prolog}

Prolog is a declarative programming language. 
Unlike imperative languages like Java, or functional languages like ML, programs written in Prolog do not define algorithms by specifying a sequential list of operations. 
Instead, constraints are placed on variables, and it is left to the Prolog implementation to determine variable bindings that satisfy those constraints. 

More precisely, the constraints in a Prolog program are written as a set of Horn clauses. 
A clause is a disjunction of literals; it is a Horn clause if it has at most one positive literal. 
The program also contains query predicates, and the goal of execution is to exhibit a set of variable bindings that satisfy these queries, or report failure if none exists. 
This is done by unifying the query predicates with the Horn clauses.

Consequently, compilation of Prolog programs requires generating an algorithm to perform unification, in addition to the usual tasks of parsing syntax into a tree and translating it to the target language.

In addition, Prolog programs can backtrack. 
If variable bindings are made, and subsequently encountered variables have no valid bindings, then the initial bindings must be undone and changed. 
This can also happen if all the constraints are satisfied, but the user requests an alternate answer. 
As such, the compiler must also allow for such backtracking.

\subsection{The Byrd Box Model}

% Reference the formal semantics paper

A helpful description of Prolog's control flow is given by the Byrd box model. 
A typical programming function can be modelled as a box with two ports: a ``call'' port for calling into the function and a ``success'' port when the function returns. 
%A Prolog predicate is viewed as a procedure with four ports: two ways in which control can be passed to the predicate

[Describe Byrd Box Model in detail]

\subsection{The WAM}

% Reference the WAM manual
[Describe the WAM in brief, relate it to the Byrd Box model, and reference the manual.]

\subsection{Unification}

[Describe how unification works in general]

\subsection{Pure Prolog}

The success criterion for the project is succinctly described as an implementation of ``pure'' Prolog. 
However, pure Prolog is not an entirely well-defined delineation, so I will clarify which elements this includes.

Pure Prolog includes Horn clauses of the syntactic form \verb|Head :- Body|, where \verb|Head| is a positive literal \verb|h| and \verb|Body| is a comma-separated list of positive literals \verb|b_1, ..., b_n|. 
It also includes query terms of the syntactic form \verb|:- q_1, ..., q_n|.

Pure Prolog does not include any built-in predicates, such as \verb|atomic/1|. 
It also excludes arithmetic infix operators like \verb|+| and \verb|-|, and the \verb|is| keyword. 
It does not include the cut operator \verb|!|.

The final project was extended to include several of these elements, including arithmetic evaluation and a selection of built-in predicates.

\newpage

\section{Preparation}

% Introduction and Preparation: 3100 words

% Describe continuations and CPS
% Relate continuations to Byrd Box
% Talk about learning ML properly

\subsection{Programming in Continuation-Passing Style}

Typically in programming, we work with functions or procedures of some kind. 
A function call takes some parameters, branches to another point of code, computes a result, and branches back to the point of calling to continue execution.

Continuation-Passing Style (CPS) is an alternative to this paradigm. 
In pure CPS, there is no concept of ``returning'' a value. 
When a function $f$ is called, it is provided with a continuation $k$ as one of its parameter, which is a function representing the next step of computation after $f$ completes. 

The usefulness of CPS becomes clear when one considers giving multiple continuation functions, say $k1$ and $k2$, to a function $f$. 
This gives an elegant way of forking execution in two or more directions. 
In a non-CPS program, such a fork would require $f$ to return a value and then its caller would test the value and choose a direction of execution on that basis. 
In CPS, $f$ doesn't have to encode the information in a type-restricted return value.

The software produced for this project uses a mixture of conventional style and CPS. 
The unification algorithm is implemented in conventional style: it accepts two terms to unify and a set of the existing substitutions that must remain consistent, and returns the updated set of substitutions. 
CPS is leveraged in the interpreter and in compiled output to implement the backtracking control flow of Prolog.

[Relate continuations to the Byrd Box model]

%%%

\subsection{ML as an implementation language}

I studied ML as part of the first year course, but it was in the context of an introduction to the foundations of Computer Science. 
Thus, the actual ML proficiency that was taught did not go beyond a very basic level, with programs consisting of just a couple of functions which were a handful of lines long. 
There is a large gap between a simple sorting algorithm and an implementation of a programming language. 
To address this, I spent a portion of my preparation time studying ``ML for the Working Programmer'', a standard textbook on the language, to develop the necessary proficiency and learn the use of advanced ML concepts like modules that help with programming at the necessary scale.

[Mention SML/NJ as exact language]

\newpage

\section{Implementation}

% Implementation: 4700 words

% Wildcards

Implementation took place over a span of around 14 weeks, starting in the second week of December and finishing in mid-March. 
Compared to the original work schedule, this represented a significant delay, as implementation should have started in early November but was pushed back due to heavy course workload. 
By mid-January, work had caught up with the original schedule and proceeded at more or less the planned rate from then on.

\subsection{Unit Testing}

Being a relatively little-used language, particularly for building substantial pieces of software, the libraries available for ML are quite limited. 
With regard to unit testing, the main library I came across was SMLUnit. 
I looked into using it, but found that while it would work, it was a very heavyweight solution.

The alternative approach was to write my own unit testing framework. 
I looked into this, and found that it could be done very easily. 
ML is not completely free of side-effects, but code written in ML tends towards having very few, which makes it very amenable to unit testing. 
Thus, I was able to write a very small unit tester - about 40 lines of code - that was sufficient for the needs of this project.

The main function is \verb|checkResult()|, which takes a test name, the actual and expected results of a function, and a function for comparing the two. 
It prints success or failure as appropriate. 
It maintains two internal counters for the number of tests which pass or fail, and a \verb|conclude()| function will print and reset the counters.

A set of test cases is simply a function consisting of calls to \verb|checkResult()|, and ending with a call to \verb|conclude()|.

It was important, of course, that the unit tester be completely correct so that test failures would be properly detected. 
To ensure this, I had the code for the unit tester code-reviewed by a fellow Part II student.

\subsection{Datatypes}

% Different term types distinguish strings from numbers.

A \verb|token| datatype was needed to represent the token types that could be recognised during lexing, as described in \S3.4. 
The \verb|INT|, \verb|FLOAT|, \verb|ATOM| and \verb|VARIABLE| tokens contain relevant values, while all other token types have no internal values. 
The only remarkable aspect of this datatype is that, because the \verb|FLOAT| token needs to contain a value of type \verb|real| which isn't an equality type in ML, the \verb|token| datatype isn't an equality type. 
Thus, an explicit equality function had to be defined.

A hierarchy of datatypes were needed to represent Prolog programs. 
At the bottom level, we have four types of \verb|term|s. A \verb|Term| is a typical instantiated Prolog term, consisting of a \verb|Functor| string and a list of \verb|term|s representing its arguments. 
An \verb|IntTerm| and a \verb|FloatTerm| are terms which represent integers and floats respectively. 
These must be distinct types from Prolog \verb|Term|s so that, say, the number 256 does not unify with the string ``256''. 

Finally, a \verb|Variable| represents an uninstantiated Prolog term. 
A \verb|Variable| is identified by both a name and an integer. 
The integer represents the scope of a variable, and is essential so that variables of the same name in different scopes do not alias. 
Scope `1' is specially reserved to identify variables in the query. 
When reporting a successful query, only the bindings of variables that appeared in the query are reported: the user doesn't care about the bindings of intermediate variables.

The \verb|Binding| type contains two \verb|term|s, and indicates that they are equivalent. 
It is defined to be symmetric, such that a \verb|Binding| $(A,B)$ and a \verb|Binding| $(B,A)$ are equal.

The \verb|Unifier| type contains a list of \verb|Binding|s. 
It is returned by the unification algorithm, as discussed in \S3.6, to indicate the variable bindings which were made to unify two terms. 
The ordering of the list has no semantic meaning.

The \verb|Clause| type contains a ``head'' \verb|term| and a list of ``body'' \verb|terms|, corresponding directly to the Prolog clause syntax.

The \verb|Program| type contains a list of \verb|Clause|s, and represents a complete parsed Prolog program.

The \verb|Query| type contains a list of \verb|term|s, corresponding directly to a Prolog query.

[diagram to illustrate Prolog program datatypes hierarchy]

\subsection{Prolog Lexer/Parser}

Generally in software engineering, it is best to tackle the most challenging aspects early. 
When starting the project, the unification algorithm and interpreter logic were the key areas that needed to be targetted. 
To facilitate this, I wanted to put together a ``quick and dirty'' front-end that would give me parsed programs to use as test cases.

The Prolog ISO standard includes predicates for reading and writing Prolog terms. 
I reasoned that if I were to write a Prolog program that read in another Prolog source file and wrote out the ML datatype for that program, I would effectively get a workable lexer and parser for relatively little development effort. 
In practice, the program was less trivial than I expected. 
Given that the final lexer and parser, to be discussed in the sections which follow, were not very complicated to write, it would actually have been better to just write those up-front. 
Nonetheless, the approach I took was still successful and with about a week's worth of development effort, I had a working front-end.

\subsection{Lexer}

The first step of compilation is to convert the source file, a stream of characters, into a list of tokens. 
Prolog is syntactically a very lightweight language, particularly when restricted to pure constructs. 
To tokenise the input, there are just 11 distinct token types required in the pure case, or 22 in the final version that I implemented. 
Tokenising can be done for Prolog using standard lexing techniques: a type-3 Chomsky grammar, described by a finite state machine. 

[include diagram of state machine]

For the most part, the state machine moves between an ``idle'' state and the state corresponding to a token being lexed. 
We move to the appropriate state based on the first character lexed, and move back to the idle state when whitespace is encountered. 
The only case where the first character doesn't tell us the token is for integers and floats. 
If we see a dot character, then it's a float, otherwise it's an integer. 
A further inconvenience comes from Prolog's use of the dot character as an end-of-statement marker. 
This means that an integer at the end of a line will have a dot character immediately after it. 
We can still parse unambiguously, because an end-of-statement dot must be followed by whitespace, while a floating-point dot must be followed by a digit. 
It just makes the state machine, and the corresponding code, more complex.

The implementation of the state machine includes a function for each state, with transitions represented by calls to the function of the destination state.

The lexer produces the entire list of tokens before any parsing is done. 
This is less space-efficient than an implementation that lexes the input on-demand to produce the next token in a stream, because the tokens for the entire program must be in memory at once. 
Furthermore, the lexer fails cleanly if there is a syntax error in the source file being tokenised, but doesn't provide any detailed error information, as one might expect from a commercial compiler. 
However, these improvements weren't important to the goals of the project, and thus weren't a priority.

\subsection{Parser}
% Discuss the parser: CFG, recursive descent, special hacks

Once the character stream has been tokenised, the next step in compilation is to build the token stream into a meaningful data structure. 
Prolog's syntax is representable by a context-free grammar: it is a small language, so the grammar is relatively small. 
Furthermore, it can be written in such a way as to not have left recursion, and can therefore be parsed using the standard recursive descent parsing method. 
The grammar I implemented is as follows:

\newpage

\texttt{
S $\rightarrow$ Lines EOF\\
Lines $\rightarrow$ Line DOT MoreLines\\
MoreLines $\rightarrow$ $\epsilon$ | Lines\\
Line $\rightarrow$ Query | Clause\\
Query $\rightarrow$ COLONMINUS TermList\\
Clause $\rightarrow$ Term COLONMINUS Body\\
Body $\rightarrow$ $\epsilon$ | TermList\\
TermList $\rightarrow$ Term IsTerm MoreTerms\\
IsTerm $\rightarrow$ $\epsilon$ | IS Term IsTerm\\
MoreTerms $\rightarrow$ $\epsilon$ | COMMA TermList\\
Term $\rightarrow$ ATOM Args | LEFTSQ TermList MoreList | Arith MoreArith\\
Args $\rightarrow$ $\epsilon$ | LEFTPAREN TermList RIGHTPAREN\\
MoreList $\rightarrow$ RIGHTSQ | PIPE Tail RIGHTSQ\\
Tail $\rightarrow$ VARIABLE | LEFTSQ TermList MoreList\\
Arith $\rightarrow$ ArithTerm MoreArithTerms\\
MoreArith $\rightarrow$ GREATER ArithTerm MoreArithTerms\\
.\hspace{50px} | LESS ArithTerm MoreArithTerms \\
.\hspace{50px} | EQUALS ArithTerm MoreArithTerms\\
ArithTerm $\rightarrow$ Factor MoreFactors\\
MoreArithTerms $\rightarrow$ $\epsilon$ | PLUS Arith | MINUS Arith\\
Factor $\rightarrow$ INT | FLOAT | LEFTPAREN Arith RIGHTPAREN | VARIABLE\\
MoreFactors $\rightarrow$ MULT ArithTerm | DIV ArithTerm | MOD ArithTerm
}

The parser is implemented with a function for each non-terminal. 
The function uniquely determines a rule to apply by examining the next token in the stream. 
It then implements that rule by going left-to-right through the symbols on the right-hand-side of that rule, consuming a token from the stream for each terminal in the rule, and calling the relevant function for each non-terminal.

The parser for pure Prolog could be implemented by ``pure'' recursive descent. 
However, when arithmetic was added, it was not possible to write grammar rules without left recursion that would give the desired associativity. 
Thus, it was necessary to write non-standard code to implement the grammar correctly: specifically, when parsing arithmetic terms, the earlier terms have to be ``passed along'' as arguments to later recursive calls to build the tree correctly.

\subsection{Unification}
% Discuss unification

The unification algorithm takes two arguments. 
The first is a \verb|Unifier| containing all of the variable bindings that have been made so far, which must be respected by the new unification. 
The second is a \verb|Binding|, containing the two terms which are to be unified. 
The output is a two-tuple containing a \verb|bool| and a \verb|Unifier|. 
If the unification is successful, the \verb|bool| will be \verb|true| and the \verb|Unifier| will satisfy both the original input \verb|Unifier| and the new unification.

In any case where we are unifying terms of different non-variable types, such as an \verb|IntTerm| and a \verb|FloatTerm|, unification fails right away. 

In any case where at least one term to be unified is a variable, we add the input \verb|Binding| to the input \verb|Unifier|. 
If the input \verb|Unifier| was empty, then this succeeds immediately. 
We will see shortly that this is an important base-case for validating \verb|Unifier|s. 
Otherwise, we must call \verb|validateUnifier()| to check that the updated \verb|Unifier| is consistent, as will be described below.

This leaves three cases. 
If both terms are \verb|IntTerm|s, or both terms are \verb|FloatTerm|s, unification succeeds if they are equal, returning the same input \verb|Unifier| because no new \verb|Bindings| were made. 

If both terms are Prolog \verb|Term|s, then unification succeeds if the \verb|Functor|s are equal, the arities are equal, and the arguments are unifiable. 
Testing that the arguments are unifiable involves mapping the unification function onto each pair. 
The same input unifier is passed to each of the argument unifications. 
If every unification succeeds, then the resulting \verb|Unifier|s are merged into one \verb|Unifier|. 
This \verb|Unifier| is then passed through \verb|validateUnifier()| to test that it is consistent, and returned as a success if it is.

To check that a \verb|Unifier| is consistent, \verb|validateUnifier()| takes the transitive closure of that \verb|Unifier|. 
That is, if there are two \verb|Binding|s $(A, B)$ and $(B, C)$, then $(A, C)$ is added. 
It then calls \verb|unify()| on each individual \verb|Binding|, with an empty \verb|Unifier|, to verify that every \verb|Binding| is individually consistent.

This fact that \verb|unify()| and \verb|validateUnifier()| are mutually recursive should give the reader concern as to whether this algorithm will always terminate. 
This is a valid question, and a justification will be given later on during evaluation, showing that this will indeed terminate on any valid input.

\subsection{Interpreter}
% Interpretation and continuations
% Substitutions: reference Mycroft's paper
% Scoping

The input to the interpreter is a \verb|Program| and a list of \verb|Query|s. 
For each query, the aim is to find a \verb|Unifier| that unifies each term in the query with the head of some clause in the program. 
If the clause has a body, then the terms in the body also have to be unified with a clause in the program.

At a given step of execution, there is a term which must be satisfied, a success continuation to call when the term is satisfied, and a failure continuation to call if the term cannot be satisfied. There is also a list of program clauses left to try to unify the term with. 
Execution proceeds by taking the first clause off the list and attempting to unify the head of the clause with the term to be satisfied. 

[ Finish describing interpreter control flow, and talk about how substitutions work ]

\subsection{Compiler}
% Compiler

[ Describe the source-to-source compiler ]

\newpage

\section{Evaluation}

% Evaluation and Conclusion: 2400 words

The most important aspect of an implementation of a programming language is correctness. 
A fast implementation is worth nothing if it does not produce the correct result.

To establish the correctness of my implementation, I put together a collection of sample Prolog programs, both by writing my own targetted programs that tested specific elements of the language, and by searching online for code fragments. 
I then compared the output of the program when run by my implementation with the output when run with the existing publicly-available SWI-Prolog implementation to verify that there was no difference.

\subsection{Termination of Unification Algorithm}

As mentioned in \S3.6, the unification algorithm is implemented by two mutually recursive functions, \verb|unify()| and \verb|validateUnifier()|. The following shows that the algorithm will always terminate.

[to write]

\subsection{Implementing ML with continuations}

[ Emphasise the simplicity of the interpreter thanks to the use of continuations ]

\subsection{Benefits of compiling to ML}

[ Collect and display data showing the performance gains of the compiler over the interpreter ]

%100-line interpreter shows effectiveness of continuations

\newpage

\section{Conclusion}

Both success criteria for the project were met. Both an interpreter for Prolog programs and a source-to-source compiler from Prolog to ML were written and shown to be correct with a high degree of confidence, through extensive testing. Continuations were found to be a concise and powerful way to express the backtracking behaviour of Prolog. Pre-compilation of a Prolog source program to ML was shown to give visible performance improvements compared to interpreting. After initial scheduling setbacks, the project work proceeded in a steady, structured manner. 

\end{document}
