%%%%%%%%%%%%%%% Updated by MR March 2007 %%%%%%%%%%%%%%%%
\documentclass[12pt]{article}
\usepackage{a4wide}

\newcommand{\al}{$<$}
\newcommand{\ar}{$>$}

\parindent 0pt
\parskip 6pt

\begin{document}

\thispagestyle{empty}

\rightline{\large{Ciaran Deasy}}
\medskip
\rightline{\large{Churchill College}}
\medskip
\rightline{\large{cfd27}}

\vfil

\centerline{\large Computer Science Tripos, Part II}
\vspace{0.4in}
\centerline{\Large\bf A Prolog Compiler with Continuations}
\vspace{0.3in}
\centerline{\large 2013/14}
\vspace{2.5in}

\newpage
\hspace{5px}
\newpage

\vfil

\centerline{\large Ciaran Deasy, Churchill College}
\vspace{0.4in}
\centerline{\Large\bf A Prolog Compiler with Continuations}
\vspace{0.3in}
\centerline{\large Computer Science Tripos, Part II, 2014}
\vspace{0.1in}
\centerline{ ***** words}
\vspace{0.25in}

{\bf Author:} Ciaran Deasy\\
{\bf College:} Churchill College

\vspace{0.25in}

{\bf Project Originator:} Alan Mycroft\\
{\bf Project Supervisor:} Alan Mycroft

\vspace{0.25in}

{\bf Aim:}\\
The purpose of this project was to produce two implementations of the Prolog programming language, one being an interpreter and the other a compiler outputting source ML code. The implementations were to be written in ML and use continuation-passing style to implement the traditionally awkward backtracking behaviour of Prolog in a simple and intuitive way. The implementations were to be extensive, but not exhaustive. 

\vspace{0.25in}

{\bf Work completed:}\\
Both implementations of Prolog were completed as planned. They were tested for correctness on a wide range of sample programs, and their relative performance was measured.

\vspace{0.25in}

{\bf Special Difficulties:} None

{\bf Declaration of Originality:}
I, Ciaran Deasy of Churchill College, being a candidate for Part II of the Computer Science Tripos, hereby declare that this dissertation and the work described in it are my own work, unaided except as may be specified below, and that the dissertation does not contain material that has already been used to any substantial extent for a comparable purpose. 

Signed %TODO

Date %TODO

\vfil
\eject

\section*{Table of Contents}

%TODO
[TODO]

\newpage

\section{Introduction}

% Introduction and Preparation: 3100 words

% Talk about the WAM
% Talk about pure Prolog
% Talk about Prolog generally
% Byrd Box Model
% SML/NJ
% Unification of terms

\subsection{Project Overview}

The purpose of this project was to produce two implementations of the Prolog programming language, written in ML. 
The first implementation was an interpreter, taking as input a valid pure Prolog source file and outputting the result of running that file, and the second implementation was a compiler, taking the same input and outputting an equivalent ML program. 
The internal implementation was to use continuation-passing style, a technique that has been previously used to good effect to implement backtracking algorithms, with the aim of deciding whether this was a useful and intuitive way of implementing the Prolog language. 
The project also sought to investigate the potential gains of pre-compiling a Prolog program, compared with simply interpreting it.

\subsection{Prolog}

Prolog is a declarative programming language. 
Unlike imperative languages like Java, or functional languages like ML, programs written in Prolog do not define algorithms by specifying a sequential list of operations. 
Instead, constraints are placed on variables, and it is left to the Prolog implementation to determine variable bindings that satisfy those constraints. 

More precisely, the constraints in a Prolog program are written as a set of Horn clauses. 
A clause is a disjunction of literals; it is a Horn clause if it has at most one positive literal. 
The program also contains query predicates, and the goal of execution is to exhibit a set of variable bindings that satisfy these queries, or report failure if none exists. 
This is done by unifying the query predicates with the Horn clauses.

Consequently, compilation of Prolog programs requires generating an algorithm to perform unification, in addition to the usual tasks of parsing syntax into a tree and translating it to the target language.

In addition, Prolog programs can backtrack. 
If variable bindings are made, and subsequently encountered variables have no valid bindings, then the initial bindings must be undone and changed. 
This can also happen if all the constraints are satisfied, but the user requests an alternate answer. 
As such, the compiler must also allow for such backtracking.

\subsubsection{Terms}

Prolog's only datatype is the term. 
A term can be either an atom, a variable or a compound term. 
An atom is a numerical or string literal. 
A variable is an unbound term which can be bound to any other term, such that that term replaces all occurrences of the variable. 
A compound term consists of a functor symbol, which is just a string literal, and one or more argument terms.

\subsubsection{Clauses}

Prolog programs are made up of clauses. 
A clause consists of a head term and a list of body terms, with the semantic meaning that the head term is true if the body terms can be shown to be true. 

Prolog clauses are based on Horn clauses in first-order logic. 
A Horn clause is a disjunction of literals containing at most one positive literal. 
The body terms in a Prolog clause correspond to the negated literals in a Horn clause, and the head term corresponds to the positive literal. 
If all of the body terms can be shown to be true, then for the Horn clause to be true, it must be the case that the head term is true. 

\subsubsection{Queries and Control Flow}

Execution 

\subsubsection{Unification}

[Describe how unification works in general]

Prolog's execution proceeds by performing unification of terms. Two terms unify if they have the same functor symbol and the same arity, and each $i$th argument in one term unifies with the corresponding $i$th argument in the other term. Performing unification in Prolog involves finding a consistent set of variable bindings such that two input terms unify successfully, or determining that no such set exists. A set of variable bindings is consistent if no variable is bound to two distinct and non-unifiable terms. For a successful unification, the variable bindings must be consistent not only with each other, but with all variable bindings made by earlier unifications.

\subsection{The Byrd Box Model}

% Reference the formal semantics paper

A helpful description of Prolog's control flow is given by the Byrd box model. 
A typical programming function can be modelled as a box with two ports: a ``call'' port for calling into the function and a ``success'' port when the function returns. 
Once a function call returns, it is never re-entered.
In Prolog, however, a predicate may find zero, one, or many answers to a call. 
If there is no solution, then control leaves through a ``fail'' port, and enters an earlier predicate's ``redo'' port.
A Prolog predicate is therefore viewed as a procedure with four ports: two ways in which control can be passed to the predicate, and two ways in which it can leave.
This is called the Byrd box model.

\subsection{The WAM}

% Reference the WAM manual

Warren's Abstract Machine (``the WAM'') is the most common basis for implementing Prolog. 
It consists of a memory architecture and an instruction set. 
The memory architecture describes how to lay out Prolog terms in a heap structure, while the instruction set describes operations for manipulating this structure, corresponding to familiar primitive Prolog operations like unification. 

Clearly from the above description of the Byrd box model, it is necessary to have some mechanism that maintains information about predicate evaluations so that they can be re-entered through the ``redo'' port. 
To this end, the WAM also describes a stack of environments, whereby the bindings made by unifying predicates are tracked so that they can be undone in the event of backtracking. 

A full discussion of the WAM can be found in [reference].

This project does not follow the WAM's model. 
Rather, the focus is on leveraging ML's language features to achieve a cleaner, simpler and more intuitive implementation of Prolog. 
In particular, I will describe in \S2.1 how the use of continuation-passing style removes the need for the WAM's environment stack by using ML's function closures to implicitly retain the required information.

\subsection{Pure Prolog}

The success criterion for the project is succinctly described as an implementation of ``pure'' Prolog. 
However, pure Prolog is not an entirely well-defined delineation, so I will clarify which elements this includes.

Pure Prolog includes Horn clauses of the syntactic form \verb|Head :- Body|, where \verb|Head| is a positive literal \verb|h| and \verb|Body| is a comma-separated list of positive literals \verb|b_1, ..., b_n|. 
It also includes query terms of the syntactic form \verb|:- q_1, ..., q_n|.

Pure Prolog does not include any built-in predicates, such as \verb|atomic/1|. 
It also excludes arithmetic infix operators like \verb|+| and \verb|-|, and the \verb|is| keyword. 
It does not include the cut operator \verb|!|.

The final project was extended to include several of these elements, including arithmetic evaluation and a selection of built-in predicates.

\newpage

\section{Preparation}

% Introduction and Preparation: 3100 words

% Describe continuations and CPS
% Relate continuations to Byrd Box
% Talk about learning ML properly

\subsection{Programming in Continuation-Passing Style}

Typically in programming, we work with functions or procedures of some kind. 
A function call takes some parameters, branches to another point of code, computes a result, and branches back to the point of calling to continue execution.

Continuation-Passing Style (CPS) is an alternative to this paradigm. 
In pure CPS, there is no concept of ``returning'' a value. 
When a function $f$ is called, it is provided with a continuation $k$ as one of its parameter, which is a function representing the next step of computation after $f$ completes. 

The usefulness of CPS becomes clear when one considers giving multiple continuation functions, say $k1$ and $k2$, to a function $f$. 
This gives an elegant way of forking execution in two or more directions. 
In a non-CPS program, such a fork would require $f$ to return a value and then its caller would test the value and choose a direction of execution on that basis. 
In CPS, $f$ doesn't have to encode the information in a type-restricted return value.

The software produced for this project uses a mixture of conventional style and CPS. 
The unification algorithm is implemented in conventional style: it accepts two terms to unify and a set of the existing substitutions that must remain consistent, and returns the updated set of substitutions. 
CPS is leveraged in the interpreter and in compiled output to implement the backtracking control flow of Prolog.

[Relate continuations to the Byrd Box model]

%%%

\subsection{ML as an implementation language}

I studied ML as part of the first year course, but it was in the context of an introduction to the foundations of Computer Science. 
Thus, the actual ML proficiency that was taught did not go beyond a very basic level, with programs consisting of just a couple of functions which were a handful of lines long. 
There is a large gap between a simple sorting algorithm and an implementation of a programming language. 
To address this, I spent a portion of my preparation time studying ``ML for the Working Programmer'', a standard textbook on the language, to develop the necessary proficiency and learn the use of advanced ML concepts like modules that help with programming at the necessary scale.

[Mention SML/NJ as exact language]

\newpage

\section{Implementation}

% Implementation: 4700 words

% Wildcards

Implementation took place over a span of around 14 weeks, starting in the second week of December and finishing in mid-March. 

\subsection{Unit Testing}

Being a relatively little-used language, particularly for building substantial pieces of software, the libraries available for ML are quite limited. 
With regard to unit testing, the main library I came across was SMLUnit. 
I looked into using it, but found that while it would work, it was a very heavyweight solution.

The alternative approach was to write my own unit testing framework. 
I looked into this, and found that it could be done very easily. 
ML is not completely free of side-effects, but code written in ML tends towards having very few, which makes it very amenable to simple unit testing. 
Thus, I was able to write a very small unit tester - about 40 lines of code - that was sufficient for the needs of this project.

The main function is \verb|checkResult()|, which takes a test name, the actual and expected results of a function, and a function for comparing the two. 
It prints success or failure as appropriate. 
It maintains two internal counters for the number of tests which pass or fail, and a \verb|conclude()| function to be called at the end of a test run to print and reset the counters.

A set of test cases is simply a function consisting of calls to \verb|checkResult()|, and ending with a call to \verb|conclude()|.

It was important, of course, that the unit tester be completely correct so that test failures would be properly detected. 
To ensure this, I had the code for the unit tester code-reviewed by a fellow Part II student.

\subsection{Datatypes}

% Lists!

For the implementations, a hierarchy of datatypes were needed to represent Prolog programs, as well as datatypes to represent the interpreter's and compiler's internal state. 

\subsubsection{Lexer tokens}

A \verb|token| datatype was needed to represent the token types that could be recognised during lexing, as described in \S3.4. 
The \verb|INT|, \verb|FLOAT|, \verb|ATOM| and \verb|VARIABLE| tokens contain relevant values, while all other token types have no internal values. 
The only remarkable aspect of this datatype is that, because the \verb|FLOAT| token needs to contain a value of type \verb|real| which isn't an equality type in ML, the \verb|token| datatype isn't an equality type. 
Thus, an explicit equality function had to be defined.

\subsubsection{Terms}

At the bottom level, we have four types of \verb|term|s. A \verb|Term| is a typical instantiated Prolog term, consisting of a \verb|Functor| string and a list of \verb|term|s representing its arguments. 
An \verb|IntTerm| and a \verb|FloatTerm| are terms which represent integers and floats respectively. 
These must be distinct types from Prolog \verb|Term|s so that, say, the number 256 does not unify with the string ``256''. 

Finally, a \verb|Variable| represents an uninstantiated Prolog term. 
A \verb|Variable| is identified by both a name and an integer. 
The integer represents the scope of a variable, and is essential so that variables of the same name in different scopes do not alias. 
Scope `1' is specially reserved to identify variables in the query. 
When reporting a successful query, only the bindings of variables that appeared in the query are reported: the user doesn't care about the bindings of intermediate variables.
Thus, by reserving scope `1' for such variables, all other bindings can be easily filtered out.

\subsubsection{Variable Bindings}

The \verb|Binding| type contains two \verb|term|s, and indicates that they are equivalent. 
It is defined to be symmetric, such that a \verb|Binding| $(A,B)$ and a \verb|Binding| $(B,A)$ are equal.

The \verb|Unifier| type contains a list of \verb|Binding|s. 
It is returned by the unification algorithm, as discussed in \S3.6, to indicate the variable bindings which were made to unify two terms. 
The ordering of the list has no semantic meaning.
During unification, there may be \verb|Term|-to-\verb|Term| bindings generated when verifying consistency, but they aren't returned in the unification result because they contain no useful information.

\subsubsection{Prolog programs}

The \verb|Clause| type contains a ``head'' \verb|term| and a list of ``body'' \verb|terms|, corresponding directly to the Prolog clause syntax.

The \verb|Program| type contains a list of \verb|Clause|s, and represents a complete parsed Prolog program.

The \verb|Query| type contains a list of \verb|term|s, corresponding directly to a Prolog query.

[diagram to illustrate Prolog program datatypes hierarchy]

\subsection{Prolog Lexer/Parser}

Generally in software engineering, it is best to tackle the most challenging aspects early. 
When starting the project, I identified the unification algorithm and interpreter logic as the key areas that needed to be developed early. 
To facilitate this, I wanted to put together a ``quick and dirty'' front-end that would give me parsed programs to use as test cases.

The Prolog ISO standard includes predicates for reading and writing Prolog terms. 
I reasoned that if I were to write a Prolog program that read in another Prolog source file and wrote out the ML datatype for that program, I would effectively get a working lexer and parser for relatively little development effort. 

The implementation was conceptually simple. 
The \verb|read| predicate was called to read in clauses and queries from the source file. 
These inputs were successively syntactically split up into terms and then into individual atoms, and these were printed to an output file in the appropriate format for the ML datatype I described in \S3.2 above.

The development of the program was straightforward, but less so than I expected. 
Given that the final lexer and parser, to be discussed in the sections which follow, were not very much more complicated to write, in hindsight it would actually have been better to just write those up-front. 
Work on the important areas would have started a couple of weeks later, but I would have saved time.
Nonetheless, the approach I took was still successful and with about a week's worth of development effort, I had a working front-end.

\subsection{Lexer}

The first step of compilation is to convert the source file, a stream of characters, into a list of tokens. 
Prolog is syntactically a very lightweight language, particularly when restricted to pure constructs. 
To tokenise the input, there are just 11 distinct token types required in the pure case, or 23 in the final version that I implemented. 
Tokenising can be done for Prolog using standard lexing techniques: a type-3 Chomsky grammar, described by a finite state machine. 

[include diagram of state machine]

For the most part, the state machine moves between an ``idle'' state and the state corresponding to a token being lexed. 
We move to the appropriate state based on the first character lexed, and move back to the idle state when whitespace is encountered. 
The only case where the first character doesn't tell us the token is for integers and floats. 
If we see a dot character, then it's a float, otherwise it's an integer. 
A further inconvenience comes from Prolog's use of the dot character as an end-of-statement marker. 
This means that an integer at the end of a line will have a dot character immediately after it. 
We can still parse unambiguously, because an end-of-statement dot must be followed by whitespace, while a floating-point dot must be followed by a digit. 
It just makes the state machine, and the corresponding code, more complex.

The implementation of the state machine includes a function for each state, with transitions represented by calls to the function of the destination state.

The lexer produces the entire list of tokens before any parsing is done. 
This is less space-efficient than an implementation that lexes the input on-demand to produce the next token in a stream, because the tokens for the entire program must be in memory at once. 
Furthermore, the lexer fails cleanly if there is a syntax error in the source file being tokenised, but doesn't provide any detailed error information, as one might expect from a commercial compiler. 
However, these improvements weren't important to the goals of the project, and thus weren't a priority.

\subsection{Parser}
% Discuss the parser: CFG, recursive descent, special hacks

Once the character stream has been tokenised, the next step in compilation is to build the token stream into a meaningful data structure. 
Prolog's syntax is representable by a context-free grammar: it is a small language, so the grammar is relatively small. 
Furthermore, it can be written in such a way as to not have left recursion, and can therefore be parsed using the standard recursive descent parsing method. 
The grammar I implemented is as follows:

\newpage

\texttt{
S $\rightarrow$ Lines EOF\\
Lines $\rightarrow$ Line DOT MoreLines\\
MoreLines $\rightarrow$ $\epsilon$ | Lines\\
Line $\rightarrow$ Query | Clause\\
Query $\rightarrow$ COLONMINUS TermList\\
Clause $\rightarrow$ Term COLONMINUS Body\\
Body $\rightarrow$ $\epsilon$ | TermList\\
TermList $\rightarrow$ Term IsTerm MoreTerms\\
IsTerm $\rightarrow$ $\epsilon$ | IS Term IsTerm\\
MoreTerms $\rightarrow$ $\epsilon$ | COMMA TermList\\
Term $\rightarrow$ ATOM Args | LEFTSQ TermList MoreList | Arith MoreArith\\
Args $\rightarrow$ $\epsilon$ | LEFTPAREN TermList RIGHTPAREN\\
MoreList $\rightarrow$ RIGHTSQ | PIPE Tail RIGHTSQ\\
Tail $\rightarrow$ VARIABLE | LEFTSQ TermList MoreList\\
Arith $\rightarrow$ ArithTerm MoreArithTerms\\
MoreArith $\rightarrow$ GREATER ArithTerm MoreArithTerms\\
.\hspace{50px} | LESS ArithTerm MoreArithTerms \\
.\hspace{50px} | EQUALS ArithTerm MoreArithTerms\\
ArithTerm $\rightarrow$ Factor MoreFactors\\
MoreArithTerms $\rightarrow$ $\epsilon$ | PLUS Arith | MINUS Arith\\
Factor $\rightarrow$ INT | FLOAT | LEFTPAREN Arith RIGHTPAREN | VARIABLE\\
MoreFactors $\rightarrow$ MULT ArithTerm | DIV ArithTerm | MOD ArithTerm
}

The parser is implemented with a function for each non-terminal. 
The function uniquely determines a rule to apply by examining the next token in the stream. 
It then implements that rule by going left-to-right through the symbols on the right-hand-side of that rule, consuming a token from the stream for each terminal in the rule, and calling the relevant function for each non-terminal.

% Reference a compiler book

The parser for pure Prolog could be implemented by ``pure'' recursive descent. 
However, when arithmetic was added, it was not possible to write grammar rules without left recursion that would give the desired associativity. 
Thus, it was necessary to write non-standard code to implement the grammar correctly: specifically, when parsing arithmetic terms, the earlier terms have to be ``passed along'' as arguments to later recursive calls to build the tree correctly.

\subsection{Unification}

\subsubsection{The signature}

The unification algorithm takes two arguments. 
The first is a \verb|Unifier| containing all of the variable bindings that have been made so far, which must be respected by the new unification. 
The second is a \verb|Binding|, containing the two terms which are to be unified. 
The output is a two-tuple containing a \verb|bool| and a \verb|Unifier|. 
If the unification is successful, the \verb|bool| will be \verb|true| and the \verb|Unifier| will satisfy both the original input \verb|Unifier| and the new unification.

\subsubsection{Conditions for success}

In any case where we are unifying terms of different non-variable types, such as an \verb|IntTerm| and a \verb|FloatTerm|, unification fails right away. 

In any case where at least one term to be unified is a variable, we add the input \verb|Binding| to the input \verb|Unifier|. 
If the input \verb|Unifier| was empty, then there can be no inconsistency, so unification succeeds immediately. 
We will see shortly that this is an important base-case for validating \verb|Unifier|s. 
Otherwise, we must call \verb|validateUnifier()| to check that the updated \verb|Unifier| is consistent, as will be described below.

This leaves three cases. 
If both terms are \verb|IntTerm|s, or both terms are \verb|FloatTerm|s, unification succeeds if and only if they are equal, returning the same input \verb|Unifier| because no new \verb|Bindings| were made. 

Finally, if both terms are Prolog \verb|Term|s, then unification succeeds if and only if the \verb|Functor|s are equal, the arities are equal, and the arguments are pairwise unifiable. 
Testing that the arguments are unifiable involves mapping the unification function onto each pair. 
The same input unifier is passed to each of the argument unifications. [WRONG]
If every unification succeeds, then the resulting \verb|Unifier|s are merged into one \verb|Unifier|. 
This \verb|Unifier| is then passed through \verb|validateUnifier()| to test that it is consistent, and returned as a success if it is.

\subsubsection{Checking consistency}

%To check that a \verb|Unifier| is consistent, \verb|validateUnifier()| takes the transitive closure of that \verb|Unifier|. 
%That is, if there are two \verb|Binding|s $(A, B)$ and $(B, C)$, then $(A, C)$ is added. 
%It then calls \verb|unify()| on each individual \verb|Binding|, with an empty \verb|Unifier|, to verify that every \verb|Binding| is individually consistent.

When a \verb|Binding| is to be added to a \verb|Unifier|, it is necessary to check that it doesn't introduce any inconsistencies. 
To do this, we check the new \verb|Binding| against all the existing \verb|Binding|s to get a list of transitive \verb|Binding|s. 
Any two \verb|Binding|s $(A,B)$ and $(B,C)$ give a transitive \verb|Binding| $(A,C)$.

These transitive \verb|Binding|s are then checked individually in isolation to see that they are consistent. 
This is done by calling \verb|unify()| with an empty \verb|Unifier| for each \verb|Binding| to be checked. 
If all of these unifications succeed, then the input new \verb|Binding| and all of the transitive \verb|Binding|s are added to the input \verb|Unifier| to give a new candidate \verb|Unifier|.

If the individual unifications did not produce any additional \verb|Binding|s, then the candidate \verb|Unifier| is returned as an answer. 
However, if they did, then each such \verb|Binding| has to be added to the \verb|Unifier| by calling \verb|unify()|.

To illustrate the consistency check, consider an example. 
Say we have a \verb|Unifier| containing two \verb|Bindings|: \verb|X = foo(A)| and \verb|Y = foo(B)|. 
We call \verb|unify()| to add a new \verb|Binding| \verb|X = Y|. 
The consistency check will add three transitive bindings: \verb|X = foo(B)|, \verb|Y = foo(A)| and \verb|foo(A) = foo(B)|. 
It will then check that each of these transitive bindings is consistent by calling \verb|unify()| with an empty \verb|Unifier|. 
All three will succeed, and we will get a candidate \verb|Unifier| containing all of the bindings mentioned so far.
However, the third unification will generate another new binding \verb|A = B|. 
This new binding has to be added to the candidate \verb|Unifier|, so we call \verb|unify()| with the candidate \verb|Unifier| and this new \verb|Binding| that we wish to add.

This fact that \verb|unify()| and \verb|validateUnifier()| are mutually recursive should give the reader concern as to whether this algorithm will always terminate. 
This is a valid question, and a justification will be given later on during evaluation, showing that this will indeed terminate on any valid input.

\subsection{Interpreter}
% Interpretation and continuations
% Substitutions: reference Mycroft's paper
% Scoping

The input to the interpreter is a \verb|Program| and a list of \verb|Query|s. 
For each query, the aim is to find a \verb|Unifier| that unifies each term in the query with the head of some clause in the program. 
If we visualise a queue of terms that need to be unified with a clause, then the query terms are the initial contents of that queue. 
If the clause with which a term is unified has a body, then the terms in the body also have to be unified with a clause in the program.
The unified term is therefore removed from the queue and the body terms are added to the front of the queue.

% Diagram of queue, unification, expansion

At a given step of execution, there is a term at the front of the queue which must be satisfied, and a list of clauses with which to try to unify it. 
Execution proceeds by taking a clause off the list and attempting the unification. 
There are success and failure continuation functions, which are called based on the outcome of the unification.
The success continuation is the execution of the rest of the terms in the queue, while the failure continuation backtracks to a previously completed queue item.

% Diagram of continuations



[ Finish describing interpreter control flow, and talk about how substitutions work ]

\subsection{Compiler}
% Compiler

[ Describe the source-to-source compiler ]

\newpage

\section{Evaluation}

% Evaluation and Conclusion: 2400 words

% Future Improvements

The most important aspect of an implementation of a programming language is correctness. 
A fast implementation is worth nothing if it does not produce the correct result.

To establish the correctness of my implementation, I put together a collection of sample Prolog programs, both by writing my own targetted programs that tested specific elements of the language, and by searching online for code fragments. 
I then compared the output of the program when run by my implementation with the output when run with the existing publicly-available SWI-Prolog implementation to verify that there was no difference.

\subsection{Termination of Unification Algorithm}

As mentioned in \S3.6, the unification algorithm is implemented by two mutually recursive functions, \verb|unify()| and \verb|validateUnifier()|. The following shows that the algorithm will always terminate.

[to write]

\subsection{Implementing ML with continuations}

[ Emphasise the simplicity of the interpreter thanks to the use of continuations ]

\subsection{Benefits of compiling to ML}

[ Collect and display data showing the performance gains of the compiler over the interpreter ]

%100-line interpreter shows effectiveness of continuations

\newpage

\section{Conclusion}

Both success criteria for the project were met. Both an interpreter for Prolog programs and a source-to-source compiler from Prolog to ML were written and shown to be correct with a high degree of confidence, through extensive testing. Continuations were found to be a concise and powerful way to express the backtracking behaviour of Prolog. Pre-compilation of a Prolog source program to ML was shown to give visible performance improvements compared to interpreting. After initial scheduling setbacks, the project work proceeded in a steady, structured manner. 

\end{document}
